**Задание**

Загрузите файл: [GitHub - sultanmurad/spark_example_files](https://github.com/sultanmurad/spark_example_files)

Выполните следующую логику:

1. С помощью модуля pandas преобразуйте файл из .xlsx в .csv формат
2. Инициализируйте Spark-сессию
3. Создайте dataframe из скачанного файла
4. Подсчитайте следующие показатели:

* Количество строк в файле
* Количество уникальных клиентов
* В какой стране совершается большинство покупок
* Даты самой ранней и самой последней покупки на платформе

5. Проведите RFM-анализ клиентов платформы. Что такое RFM-анализ? Обычно RFM-анализ используется в маркетинге для оценки ценности клиента на основе его:

* **Recency** - Давность: как давно каждый покупатель совершил покупку?
* **Frequency**- Частота: Как часто они что-то покупали?
* **Monetary** - Денежная ценность: сколько денег они в среднем тратят при совершении покупок?

  Добавьте в dataframe для каждого клиента 3 новых поля, примерно такого вида

  ![64d62d525bbfb](https://github.com/UncleJoe1973/1T_course/assets/29273924/a6cab2e5-9886-48f3-9f60-3abb048a4cfd)
  
  Для каждого показателя добавьте стобец с разбиением клиентов на 3 группы. Допустим, у нас есть 3 клиента, первый клиент последний раз купил товар только в прошлом году, второй клиент в прошлом месяце, а третий клиент на прошлой неделе. Каждый из этих клиентов должен получить различные значения группы для показателя Recency - A, B и С, где А - отражает наибольшую “ценность”, а С - соответственно, наименьшую.
  
  Добавьте итоговый столбец с “суммой” значений групп по каждому показателю и сохраните в отдельный csv-файл Id только тех клиентов, у которых значения групп ААА.
  
  В качестве результата вам необходимо предоставить код написанный на spark или pyspark, а также итоговый файл.

Результат выполнения задания необходимо выложить в github/gitlab и указать ссылку на Ваш репозиторий (не забудьте: репозиторий должен быть публичным).
